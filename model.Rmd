---
title: "Stats 153 Project - Zoey"
output: pdf_document
---
```{r include = FALSE}
# Template source: https://github.com/alexpghayes/rmarkdown_homework_template
knitr::opts_chunk$set(
  echo = TRUE, # don't show code
  warning = FALSE, # don't show warnings
  message = FALSE, # don't show messages (less serious warnings)
  cache = FALSE, # set to TRUE to save results from last compilation
  fig.align = "center", # center figures
  fig.height = 4,
  out.width = "75%"
)
library(ggplot2)
library(patchwork)
library(astsa)
library(TSA)
library(tidyverse)
library(fpp2)
```

### 2. Exploratory Data Analysis

Here we explore the data. Naturally, the first plot you should make is the data itself. Point out any visible features, e.g. heteroscedasticity, seasonality, trend.
To observe the recent pattern better, we only use the last 300 data points from the time series. Each data point represents daily closure price for TSLA stock. From observing the original data, it seems that the variability of the time series data set appears to be non-constant, which is heterscedasticity. Therefore we transform original data through $f(Y_t) = log(Y_t)$.

```{r}
t = 1:300
data <- read.csv("data/TSLA.csv")
open <- data$Open
close <- data$Adj.Close
close_data = tail(close, 300)
plot.ts(close_data, main="TSLA stock closure price data", ylab="Daily closure price")
```

### Models considered: Second Order Differencing + ARMA
 
Second order differencing, observe the data, the data seems stationary without obvioud trend or seasonality. 

```{r}
diff = diff(close_data, lag=1)
second_diff = diff(diff, lag = 1)
plot.ts(second_diff, main="second order differencing on TSLA data")
acf2(second_diff, main="Series: TSLA closure price data")
```
#### Evaluation

Evaluating AIC, BIC, AICc, and time-series cross validation. Evaluate model based on how well they predict future values. 
Choose model: (1, 2, 1)(0, 0, 0)[0]. This is because observing ACF plot on data after second order differencing, there is a cut off on approximately lag=1, and Recall that for MA(q) model, the sample ACF will contain zero values for lag $|h|>q$. Therefore we try MA(1) model. Observing partial ACF plot, there is an exponential decay, indicating we should use an ARMA(p, q) model. We use the function auto.arima to build intuition on what p, q value to choose. 
```{r}
auto.arima(second_diff)
```
The model looks well on Ljung-Box statistic with all p values above 0.05. Also the ACF of residuals shows no ACF go beyond two blue band.

```{r}
model1 <- sarima(close_data, p=1, d=2, q=1, P=0, D=0, Q=0, S=0)
```
```{r}
model1$ttable
model1.acf=ARMAacf(ar=c(-0.1087), ma=c(-0.9488), lag.max = 20, pacf=FALSE)
acf(as.vector(second_diff), lag.max=20)
points(0:20, model1.acf, col='red')
cat("AIC", model1$AIC)
cat("BIC", model1$BIC)
cat("AICc", model1$AICc)
```
```{r}
model1.pacf=ARMAacf(ar=c(-0.1087), ma=c(-0.9488), lag.max = 20, pacf=TRUE)
pacf(as.vector(second_diff), lag.max=20)
points(0:19, model1.pacf, col='red')
```


```{r}
# cross validation
start_day <- 250
end_day <- 290
jump = 10
error = 0
forward_time = 10
# we are performing n-fold validation
n = (end_day - start_day) / jump

for (k in start_day:end_day) {
  train <- window(close_data, end=k-0.001)
  test <- window(close_data, start=k, end=k + forward_time - 0.01)
  forecast <- sarima.for(train, n.ahead = forward_time, p=1, d=2, q=1, P=0, D=0, Q=0, S=0)
  error = error + sum((forecast$pred - test)^2)
  k = k + 10
}
error = error / n
cat("cross validation error", error)
```

### 5. Results 
We choose model 3: 2nd-order differencing + ARMA 2A model. 
First, write out model mathematically. Let original time series stock data denoted by $
$\{X_t\}$ and second order differenced time series data denoted by $\{Z_t\}$. Then $(1 - \phi_1B) \nabla^2 X_t = (1 - \theta_1B)W_t$ or equivalently $(1-\phi_1B)Z_t = (1-\theta_1B)W_t$.
Second, estimate the parameters of your chosen model, probably in a table. 
```{r}
model1$ttable
```

Third, forecast appropriately and include a plot of your forecasted values appended to the end of your time series. Here I choose to forecast TSLA closure price for next 10 days. TODO: address uncertainty about prediction?
```{r}
plot(close_data)
forecast <- sarima.for(close_data, n.ahead = 10, p=1, d=2, q=1, P=0, D=0, Q=0, S=0)
forecast$pred
```


#### 5.1 Estimation of model parameters


<!-- ### Model considered: Exponential Smoothing -->
<!-- In this model, we choose exponential smoothing with weight $\alpha = 0.8$. We calculate $\hat{y}_{t+1} = \alpha y_t + \alpha(1-\alpha) y_{t-1} + ... + \alpha (1-\alpha)^{t-1}y_1$, where $0<\alpha<1$. -->

<!-- First, we explore and choose a good alpha value. -->
<!-- ```{r} -->
<!-- # code citation: http://uc-r.github.io/ts_exp_smoothing -->
<!-- # create training and validation of stock data -->
<!-- data.train = window(data, end=250) -->
<!-- data.test = window(data, start=251) -->
<!-- forward_time = 50 -->
<!-- # simple forecast try -->
<!-- ses.data <- ses(data.train, alpha=0.9, h=forward_time) -->
<!-- autoplot(ses.data) -->
<!-- print(typeof(ses.data$fitted)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # identify optimal alpha parameter -->
<!-- alpha <- seq(.01, .99, by = .01) -->
<!-- RMSE <- NA -->
<!-- for(i in seq_along(alpha)) { -->
<!--   fit <- ses(data.train, alpha = alpha[i], h = forward_time) -->
<!--   RMSE[i] <- accuracy(fit, data.test)[2,2] -->
<!-- } -->

<!-- # convert to a data frame and identify min alpha value -->
<!-- alpha.fit <- data_frame(alpha, RMSE) -->
<!-- alpha.min <- filter(alpha.fit, RMSE == min(RMSE)) -->

<!-- # plot RMSE vs. alpha -->
<!-- ggplot(alpha.fit, aes(alpha, RMSE)) + -->
<!--   geom_line() + -->
<!--   geom_point(data = alpha.min, aes(alpha, RMSE), size = 2, color = "blue")  -->
<!-- ``` -->


<!-- From above alpha v.s. RMSE graph, we use the optimal value $\alpha = 0.9$ (TODO: check correctness). Get residual data by removing the trend of exponential smoothing. -->
<!-- ```{r} -->
<!-- # code from Xiangxi Wang -->
<!-- # exponential filter  -->
<!-- alpha = 0.9 -->
<!-- lag = 10 -->
<!-- filter_weights = alpha^(1:lag) -->
<!-- filter_weights = filter_weights/sum(filter_weights) -->
<!-- filtered_stock = stats::filter(data, filter_weights, sides = 1) -->
<!-- # Plot the original data and fitted values -->
<!-- plot(t, data, type = 'l', main = "(a)", xlab = "Time", ylab = "Close Price") -->
<!-- lines(t, filtered_stock, col = 'red') -->

<!-- filtered_stock = na.omit(filtered_stock) -->
<!-- log_stock = data[-1:-(lag - 1)] -->
<!-- res = log_stock - filtered_stock -->
<!-- plot(res, main = "(b)", xlab = "Time", ylab = "Residuals") -->
<!-- ``` -->
<!-- Now we try to fit seasonal ARMA model on residuals after removing the trend. -->

<!-- ```{r} -->
<!-- # fit model on residual -->
<!-- acf2(res) -->
<!-- model2 <- sarima(res, p = 2, d = 1, q = 1, P = 0, D = 0, Q = 1, S = 5) -->
<!-- model2$AIC -->
<!-- model2$AICc -->
<!-- model2$BIC -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # perform cross validation evaluation -->
<!-- start_day <- 250 -->
<!-- end_day <- 290 -->
<!-- jump = 10 -->
<!-- error = 0 -->
<!-- forward_time = 10 -->
<!-- # we are performing n-fold validation -->
<!-- n = (end_day - start_day) / jump -->

<!-- for (k in start_day:end_day) { -->
<!--   train <- window(data, end=k-0.001) -->
<!--   test <- window(data, start=k, end=k + forward_time - 0.01) -->
<!--   res_model <- sarima.for(res, n.ahead = forward_time,  p = 2, d = 1, q = 1, P = 0, D = 0, Q = 1, S = 5) -->
<!--   trend_prediction <- ses(train, alpha=0.9, h=forward_time) -->
<!--   res_prediction <- res_model$pred -->
<!--   print(trend_prediction) -->
<!--   error <- error + sum((res_prediction - test)^2) -->
<!--   k = k + 10 -->
<!-- } -->
<!-- error = error / n -->
<!-- cat("cross validation error", error) -->
<!-- ``` -->

